{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgXxoDhMAiti"
      },
      "source": [
        "# Video Killed The Radio Star\n",
        "\n",
        "Notebook by David Marx ([@DigThatData](https://twitter.com/digthatdata))\n",
        "\n",
        "Shared under MIT license\n",
        "\n",
        "## What is this?\n",
        "\n",
        "Point this notebook at a youtube url and it'll make a music video for you.\n",
        "\n",
        "## How this animation technique works\n",
        "\n",
        "For each text prompt you provide, the notebook will...\n",
        "\n",
        "1. Generate an image based on that text prompt\n",
        "2. Use the generated image as the `init_image` to recombine with the text prompt to generate variations similar to the first image. This produces a sequence of extremely similar images based on the original text prompt\n",
        "3. This image sequence is then repeated several times to produce a longer sequence\n",
        "\n",
        "The technique demonstrated in this notebook was inspired by a [video](https://www.youtube.com/watch?v=WJaxFbdjm8c) created by Ben Gillin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///home/dmarx/proj/video-killed-the-radio-star\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: yt-dlp in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (2022.9.1)\n",
            "Requirement already satisfied: scipy in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (1.9.1)\n",
            "Requirement already satisfied: numpy in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (1.23.3)\n",
            "Requirement already satisfied: pandas in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (1.4.4)\n",
            "Requirement already satisfied: webvtt-py in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (0.4.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (4.11.1)\n",
            "Requirement already satisfied: toolz in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (0.12.0)\n",
            "Requirement already satisfied: lxml in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (4.9.1)\n",
            "Requirement already satisfied: python-tsp in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (0.3.1)\n",
            "Requirement already satisfied: pytokenizations in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (0.8.4)\n",
            "Requirement already satisfied: omegaconf in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from vktrs==0.0.1) (2.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from beautifulsoup4->vktrs==0.0.1) (2.3.2.post1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from omegaconf->vktrs==0.0.1) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from omegaconf->vktrs==0.0.1) (5.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from pandas->vktrs==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from pandas->vktrs==0.0.1) (2022.2.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.0 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from python-tsp->vktrs==0.0.1) (2.28.1)\n",
            "Requirement already satisfied: tsplib95<0.8.0,>=0.7.1 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from python-tsp->vktrs==0.0.1) (0.7.1)\n",
            "Requirement already satisfied: docopt in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from webvtt-py->vktrs==0.0.1) (0.6.2)\n",
            "Requirement already satisfied: pycryptodomex in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from yt-dlp->vktrs==0.0.1) (3.15.0)\n",
            "Requirement already satisfied: websockets in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from yt-dlp->vktrs==0.0.1) (10.3)\n",
            "Requirement already satisfied: certifi in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from yt-dlp->vktrs==0.0.1) (2022.6.15.1)\n",
            "Requirement already satisfied: mutagen in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from yt-dlp->vktrs==0.0.1) (1.45.1)\n",
            "Requirement already satisfied: brotli in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from yt-dlp->vktrs==0.0.1) (1.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->vktrs==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.0->python-tsp->vktrs==0.0.1) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.0->python-tsp->vktrs==0.0.1) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.0->python-tsp->vktrs==0.0.1) (1.26.12)\n",
            "Requirement already satisfied: Click>=6.0 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from tsplib95<0.8.0,>=0.7.1->python-tsp->vktrs==0.0.1) (8.1.3)\n",
            "Requirement already satisfied: Deprecated~=1.2.9 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from tsplib95<0.8.0,>=0.7.1->python-tsp->vktrs==0.0.1) (1.2.13)\n",
            "Requirement already satisfied: networkx~=2.1 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from tsplib95<0.8.0,>=0.7.1->python-tsp->vktrs==0.0.1) (2.8.6)\n",
            "Requirement already satisfied: tabulate~=0.8.7 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from tsplib95<0.8.0,>=0.7.1->python-tsp->vktrs==0.0.1) (0.8.10)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from Deprecated~=1.2.9->tsplib95<0.8.0,>=0.7.1->python-tsp->vktrs==0.0.1) (1.14.1)\n",
            "Building wheels for collected packages: vktrs\n",
            "  Building editable for vktrs (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for vktrs: filename=vktrs-0.0.1-0.editable-py3-none-any.whl size=3347 sha256=d60c4b50277959c35933f7821d7efcbedd57c4c71bdf80e3c8f605f1455e9e99\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pet86g5e/wheels/46/6b/70/251f6ff63bedd32341817f5e05d047889f0983a2a6e4098678\n",
            "Successfully built vktrs\n",
            "Installing collected packages: vktrs\n",
            "  Attempting uninstall: vktrs\n",
            "    Found existing installation: vktrs 0.0.1\n",
            "    Uninstalling vktrs-0.0.1:\n",
            "      Successfully uninstalled vktrs-0.0.1\n",
            "Successfully installed vktrs-0.0.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#pip install vktrs\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ZnTe8clZuZuj",
        "outputId": "c84405b9-357b-4f16-d7d9-990d9a35d357"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Timestamp</th>\n",
              "      <td>2022/09/26 17:24:27.079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <td>NVIDIA GeForce RTX 3090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Utilization gpu [%]</th>\n",
              "      <td>21 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Utilization memory [%]</th>\n",
              "      <td>14 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Memory used [mib]</th>\n",
              "      <td>316 MiB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Memory free [mib]</th>\n",
              "      <td>23949 MiB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               0\n",
              "Timestamp                2022/09/26 17:24:27.079\n",
              "Name                     NVIDIA GeForce RTX 3090\n",
              "Utilization gpu [%]                         21 %\n",
              "Utilization memory [%]                      14 %\n",
              "Memory used [mib]                        316 MiB\n",
              "Memory free [mib]                      23949 MiB"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @markdown # Check GPU Status\n",
        "\n",
        "from vktrs.utils import gpu_info\n",
        "\n",
        "gpu_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "cM8cux9b7F4v",
        "outputId": "52234296-48b6-4654-f256-3f66b08a194a"
      },
      "outputs": [],
      "source": [
        "# @title # 1. 🔑 Provide your API Key\n",
        "# @markdown Running this cell will prompt you to enter your API Key below. \n",
        "\n",
        "# @markdown To get your API key, visit https://beta.dreamstudio.ai/membership\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown A note on security best practices: **don't publish your API key.**\n",
        "\n",
        "# @markdown We're using a form field designed for sensitive data like passwords.\n",
        "# @markdown This notebook does not save your API key in the notebook itself,\n",
        "# @markdown but instead loads your API Key into the colab environment. This way,\n",
        "# @markdown you can make changes to this notebook and share it without concern\n",
        "# @markdown that you might accidentally share your API Key. \n",
        "# @markdown \n",
        "\n",
        "import os, getpass\n",
        "\n",
        "if True:\n",
        "    os.environ['STABILITY_KEY'] = getpass.getpass('Enter your API Key')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_nErRsnBqUO"
      },
      "outputs": [],
      "source": [
        "# embedding yt-dlp instead of CLI let's us hold on to the output filepaths\n",
        "# probably way more trouble than it's worth and should just use yt-dlp CLI\n",
        "#video_url = 'https://www.youtube.com/watch?v=WJaxFbdjm8c'\n",
        "#!yt-dlp --write-auto-subs {video_url}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zT0u4-q_fMF",
        "outputId": "ae68fc86-e05f-40b1-85fb-9edffc0dfef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max total frames: 3600\n",
            "Frames per re-ordering batch: 1\n"
          ]
        }
      ],
      "source": [
        "# @title # 4. Animation parameters\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "storyboard = OmegaConf.create()\n",
        "\n",
        "storyboard.params = dict(\n",
        "\n",
        "     video_url = 'https://www.youtube.com/watch?v=WJaxFbdjm8c' # @param {type:'string'}\n",
        "    , theme_prompt = \"extremely detailed, painted by ralph steadman and radiohead, beautiful, wow\" # @param {type:'string'}\n",
        "\n",
        "    , n_variations=1 # @param {type:'integer'}\n",
        "    , image_consistency=0.85 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "    , fps = 12 # @param {type:\"slider\", min:4, max:60, step:1}\n",
        "\n",
        "    , output_filename = 'output.mp4' # @param {type:'string'}\n",
        "    , add_caption = True # @param {type:'boolean'}\n",
        "    , display_frames_as_we_get_them = True # @param {type:'boolean'}\n",
        "\n",
        "    , optimal_ordering = True # @param {type:'boolean'}\n",
        "    , whisper_seg = True # @param {type:'boolean'}\n",
        "    , max_video_duration_in_seconds = 300 # @param {type:'integer'}\n",
        "\n",
        "\n",
        "    #, max_frames = fps * max_video_duration_in_seconds\n",
        "    , max_variations_per_opt_pass=15\n",
        "\n",
        ")\n",
        "\n",
        "storyboard.params.max_frames = storyboard.params.fps * storyboard.params.max_video_duration_in_seconds\n",
        "\n",
        "\n",
        "print(f\"Max total frames: {storyboard.params.max_frames}\")\n",
        "#print(f\"Max API requests: {int(max_frames/repeat)}\")\n",
        "\n",
        "if storyboard.params.optimal_ordering:\n",
        "\n",
        "    opt_batch_size = storyboard.params.n_variations\n",
        "    while opt_batch_size > storyboard.params.max_variations_per_opt_pass:\n",
        "        opt_batch_size /= 2\n",
        "    print(f\"Frames per re-ordering batch: {opt_batch_size}\")\n",
        "    storyboard.params.opt_batch_size = opt_batch_size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fLgCwRAg-MVy"
      },
      "outputs": [],
      "source": [
        "# Hi user! one last thing you need to do: replace the text below\n",
        "# with your song lyrics. Each non-blank line will be a separate \"scene\" in the\n",
        "# final animation.\n",
        "\n",
        "storyboard.params.user_provided_captions = \"\"\"\n",
        "Global controls will have to be imposed\n",
        "And a world governing body, will be created to enforce them\n",
        "Crises, precipitate change\n",
        "Secretly plotting your demise\n",
        "\n",
        "I wanna devise a virus\n",
        "To bring dire straits to your environment\n",
        "Crush your corporations with a mild touch\n",
        "Trash your whole computer system and revert you to papyrus\n",
        "I want to make a super virus\n",
        "Strong enough to cause blackouts in every single metropolis\n",
        "Cause they don't wanna unify us\n",
        "So fuck-it total anarchy and can't nobody stop us\n",
        "\n",
        "You see late in the evening\n",
        "Fucked up on my computer and my mind starts roaming\n",
        "I create like a heathen\n",
        "The first cycles of this virus I can send through a modem\n",
        "Infiltration hits your station\n",
        "No Microsoft or enhanced DOS will impede\n",
        "Society thinks they're safe when\n",
        "Bingo! Hard drive crashes from the rending\n",
        "A lot of hackers tried viruses before\n",
        "Vaporize your text like so much white out\n",
        "I want it where a file replication is a chore\n",
        "Lights out shut down entire White House\n",
        "I don't want just a bug that could be corrected\n",
        "I'm erecting immaculate design\n",
        "Break the nation down, section by section\n",
        "Even to the greatest minds it's impossible to find\n",
        "\n",
        "I wanna devise a virus\n",
        "To bring dire straits to your environment\n",
        "Crush your corporations with a mild touch\n",
        "Trash your whole computer system and revert you to papyrus\n",
        "I wanna devise a virus\n",
        "To bring dire straits to your environment\n",
        "Crush your corporations with a mild touch\n",
        "Trash your whole computer system and revert you to papyrus\n",
        "\n",
        "We have already planned\n",
        "The plan is programmed into every one of my thousand robots\n",
        "We will not hesitate; we will destroy the Homosapien!\n",
        "Please, stay where you are\n",
        "\n",
        "Psst, ay, I'm makin' some shit in my basement\n",
        "Bout to do it to 'em, don't tell 'em though\n",
        "Alright I love you, peace\n",
        "\n",
        "I want to develop a super virus\n",
        "Better by far than that old Y2K\n",
        "This is 3030 the time of global unification\n",
        "Break right through they\n",
        "Terminals, burn 'em all, slaves to silicon\n",
        "Corrupt politicians with leaders and their keywords\n",
        "F.B.I. and spies stealin' bombs\n",
        "De-cipitate they plans in their face and catch the fever\n",
        "Everybody loot the stores get your canned goods\n",
        "Even space stations are having a hard time\n",
        "Peacekeepers seek to take our manhood\n",
        "Which results in the form of global apartheid\n",
        "Ghettos are trash dumps with gas pumps\n",
        "Exploding and burnt out since before the great union\n",
        "The last punks walk around like masked monks\n",
        "Ready to manipulate the database or break through 'em\n",
        "Human rights come in a hundredth place\n",
        "Mass production has always been number one\n",
        "New Earth has become a repugnant place\n",
        "So it's time to spread the fear to thunder some\n",
        "\n",
        "Too long have we tried \n",
        "to extend our glorious empire out to the stars\n",
        "Only to be driven back\n",
        "\n",
        "I wanna devise a virus\n",
        "To bring dire straits to your environment\n",
        "Crush your corporations with a mild touch\n",
        "Trash your whole computer system and revert you to papyrus\n",
        "I wanna devise a virus\n",
        "To bring dire straits to your environment\n",
        "Crush your corporations with a mild touch\n",
        "Trash your whole computer system and revert you to papyrus\n",
        "\"\"\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Kk0V4RNA5gHw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "### installations and definitions\n",
        "\n",
        "#!pip install yt-dlp\n",
        "#!pip install python-tsp\n",
        "#!pip install webvtt-py # only need this if srv2 isn't available\n",
        "\n",
        "#https://github.com/explosion/tokenizations\n",
        "#!pip install pytokenizations\n",
        "\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import string\n",
        "from subprocess import Popen, PIPE\n",
        "import textwrap\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import tokenizations\n",
        "import webvtt\n",
        "\n",
        "\n",
        "#import getpass\n",
        "\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from itertools import chain, cycle\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from vktrs.youtube import (\n",
        "    YoutubeHelper,\n",
        "    parse_timestamp,\n",
        "    vtt_to_token_timestamps,\n",
        "    srv2_to_token_timestamps,\n",
        ")\n",
        "\n",
        "from vktrs.utils import remove_punctuation\n",
        "from vktrs.api import get_image_for_prompt\n",
        "\n",
        "\n",
        "def get_variations_w_init(prompt, init_image, **kargs):\n",
        "  return list(get_image_for_prompt(prompt=prompt, init_image=init_image, **kargs))\n",
        "\n",
        "def get_close_variations_from_prompt(prompt, n_variations=2, image_consistency=.7):\n",
        "  \"\"\"\n",
        "  prompt: a text prompt\n",
        "  n_variations: total number of images to return\n",
        "  image_consistency: float in [0,1], controls similarity between images generated by the prompt.\n",
        "                     you can think of this as controlling how much \"visual vibration\" there will be.\n",
        "                     - 0=regenerate each image independently without consideration for other images generated by prompt\n",
        "                     - 1=images are all completely identical\n",
        "  \"\"\"\n",
        "  images = list(get_image_for_prompt(prompt))\n",
        "  for _ in range(n_variations - 1):\n",
        "     img = get_variations_w_init(prompt, images[0], start_schedule=(1-image_consistency))[0]\n",
        "     images.append(img)\n",
        "  return images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8OaQYVfYgBH-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Download subtitles and audio from youtube\n",
        "\n",
        "video_url = storyboard.params.video_url\n",
        "helper = YoutubeHelper(video_url)\n",
        "\n",
        "# to do: check if user provided an audio filepath before attempting to download from youtube\n",
        "\n",
        "#input_audio = list(Path('.').glob('*.webm'))[0]\n",
        "input_audio = helper.info['requested_downloads'][-1]['filepath']\n",
        "!ffmpeg -y -i \"{input_audio}\" -acodec libmp3lame audio.mp3\n",
        "\n",
        "subtitle_format = helper.info['requested_subtitles']['en']['ext']\n",
        "subtitle_fpath = helper.info['requested_subtitles']['en']['filepath']\n",
        "\n",
        "\n",
        "if subtitle_format == 'srv2':\n",
        "    with open(subtitle_fpath, 'r') as f:\n",
        "        srv2_xml = f.read() \n",
        "    token_start_times = srv2_to_token_timestamps(srv2_xml)\n",
        "\n",
        "elif subtitle_format == 'vtt':\n",
        "    captions = webvtt.read(subtitle_fpath)\n",
        "    token_start_times = vtt_to_token_timestamps(captions)\n",
        "\n",
        "# If unable to download supported subtitles, force use whisper\n",
        "else:\n",
        "    storyboard.params.whisper_seg = True\n",
        "\n",
        "whisper_seg = storyboard.params.whisper_seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937,
          "referenced_widgets": [
            "afcf916e6878438a8af4aae964490265",
            "1dd8b1c7a5b84c359392957ebf15fa43",
            "7ba7cfb4b2f843f9ae7dea6edc8471b1",
            "7145a43cc7704bfea46f9f106a06f990",
            "bc93a3f7ecf04d64ac253dab98f645cb",
            "a75aba78b0fe441bb016de8e533e2e04",
            "0302dce789e54cdb96202b54ff0aa8fb",
            "8e55da1a7b9b49fd9333861c98d7354a",
            "c01e4d9874c441cbad5495ac6629b028",
            "1148a9f2996747448a902189021ab753",
            "0e8cae5d21d24d4e8c5d43cc4569676e"
          ]
        },
        "id": "73lfb0gZvGW5",
        "outputId": "eade251f-e27a-45e5-b4d6-bcc5c0dd6671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper\n",
            "  Cloning https://github.com/openai/whisper to /tmp/pip-req-build-mkdap77p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper /tmp/pip-req-build-mkdap77p\n",
            "  Resolved https://github.com/openai/whisper to commit b4308c478217f00436c387694e5e848cc87c7fb5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from whisper==1.0) (1.23.3)\n",
            "Requirement already satisfied: torch in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from whisper==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from whisper==1.0) (8.14.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from whisper==1.0) (4.19.2)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from whisper==1.0) (0.2.0)\n",
            "Requirement already satisfied: future in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.9.11)\n",
            "Requirement already satisfied: filelock in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Requirement already satisfied: requests in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (0.9.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from torch->whisper==1.0) (4.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.6.15.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dmarx/.local/share/virtualenvs/dmarx-je5LfYh2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribing audio with whisper-tiny\n",
            "elapsed: 6.365455865859985\n",
            "Transcribing audio with whisper-large\n",
            "elapsed: 27.868865489959717\n"
          ]
        }
      ],
      "source": [
        "### transcribe and segment speech using whisper\n",
        "\n",
        "if whisper_seg:\n",
        "  whispers = {\n",
        "      'tiny':None, # 5.83 s\n",
        "      'large':None # 3.73 s\n",
        "  }\n",
        "  # accelerated runtime required for whisper\n",
        "  # to do: pypi package for whisper\n",
        "  !pip install git+https://github.com/openai/whisper\n",
        "  import whisper\n",
        "  import time\n",
        "\n",
        "  options = whisper.DecodingOptions(\n",
        "      language='en',\n",
        "  )\n",
        "  for k in whispers.keys():\n",
        "      options = whisper.DecodingOptions(\n",
        "          language='en',\n",
        "      )\n",
        "      # to do: be more proactive about cleaning up these models when we're done with them\n",
        "      model = whisper.load_model(k).to('cuda')\n",
        "      start = time.time()\n",
        "      print(f\"Transcribing audio with whisper-{k}\")\n",
        "      \n",
        "      # to do: calling transcribe like this unnecessarily re-processes audio each time.\n",
        "      whispers[k] = model.transcribe(\"audio.mp3\") # re-processes audio each time, ~10s overhead?\n",
        "      print(f\"elapsed: {time.time()-start}\")\n",
        "\n",
        "  # sanitize and tokenize\n",
        "  whispers_tokens = {}\n",
        "  for k in whispers:\n",
        "    whispers_tokens[k] = [\n",
        "      remove_punctuation(tok) for tok in whispers[k]['text'].split()\n",
        "    ]\n",
        "\n",
        "  # align sequences\n",
        "  tiny2large, large2tiny = tokenizations.get_alignments( #seqdiff.diff( #= tokenizations.get_alignments(\n",
        "      whispers_tokens['tiny'],\n",
        "      whispers_tokens['large']\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.12.1+cu102'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#torch.cuda.is_available()\n",
        "#torch.__version__\n",
        "#%pip uninstall -y torch torchvision torchaudio\n",
        "#%pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WrbOEv2GIRY",
        "outputId": "32eff380-ef88-4cef-df5f-f68d0aef22ce"
      },
      "outputs": [],
      "source": [
        "# to do: move this stuff\n",
        "if whisper_seg:\n",
        "\n",
        "  idx=0\n",
        "  tokenized_prompts_tiny = []\n",
        "  for phrase_idx, phrase in enumerate(whispers['tiny']['segments']):\n",
        "    rec = {\n",
        "        'start': phrase['start'],\n",
        "        'end': phrase['end'],\n",
        "        'tokens':[],\n",
        "        'indices':[],\n",
        "    }\n",
        "\n",
        "    # TO DO: I should really use this tokenization for the alignment step to ensure the indices match up\n",
        "    for tok in phrase['text'].split():\n",
        "      tok = remove_punctuation(tok)\n",
        "      rec['tokens'].append(tok)\n",
        "      rec['indices'].append(idx)\n",
        "      idx+=1\n",
        "\n",
        "    tokenized_prompts_tiny.append(rec)\n",
        "\n",
        "  # flatten\n",
        "  token_tinyindex_segmentations = {}\n",
        "  for rec in tokenized_prompts_tiny:\n",
        "    for j, idx in enumerate(rec['indices']):\n",
        "      token_tinyindex_segmentations[idx] ={\n",
        "          'token':rec['tokens'][j],\n",
        "          'start':rec['start'],\n",
        "          'end':rec['end'],\n",
        "      }\n",
        "#token_tinyindex_segmentations\n",
        "  token_large_index_segmentations = {}\n",
        "  for i, result in enumerate(large2tiny):\n",
        "    rec_large = {'token':whispers_tokens['large'][i]}\n",
        "    for j in result:\n",
        "      rec_tiny = token_tinyindex_segmentations[j]\n",
        "      if not rec_large.get('start'):\n",
        "        rec_large['start'] = rec_tiny['start']\n",
        "        rec_large['end'] = rec_tiny['end']\n",
        "    \n",
        "    # handle null result. this could be more elegant/DRY, but this way is less confusing to me at least.\n",
        "    # basically, we're just backfilling here, so each entry will have a start and end time\n",
        "    if not rec_large.get('start'):\n",
        "      if i == 0:\n",
        "        rec_large['start'] = 0\n",
        "      else:\n",
        "        rec_prev = token_large_index_segmentations[i-1]\n",
        "        rec_large['start'] = rec_prev['start']\n",
        "        rec_large['end'] = rec_prev['end']\n",
        "    \n",
        "    token_large_index_segmentations[i] = rec_large\n",
        "\n",
        "\n",
        "\n",
        "### apply whisper-tiny segmentations to whisper-large transcriptions\n",
        "\n",
        "  token_large_phrase_segmentations = []\n",
        "  start_prev = 0\n",
        "  end_prev=0\n",
        "  current_phrase = []\n",
        "  for rec in token_large_index_segmentations.values():\n",
        "    print(current_phrase)\n",
        "    print(start_prev, end_prev, rec)\n",
        "    # we're in the same phrase as previous step\n",
        "    if rec['start'] == start_prev:\n",
        "      print(\"still in phrase\")\n",
        "      current_phrase.append(rec['token'])\n",
        "      start_prev = rec['start']\n",
        "      end_prev = rec['end']\n",
        "      continue\n",
        "  \n",
        "    # we're in the next phrase, \n",
        "    token_large_phrase_segmentations.append({\n",
        "        'tokens': current_phrase,\n",
        "        'start':start_prev,\n",
        "        'end':end_prev,\n",
        "    })\n",
        "    current_phrase = []\n",
        "\n",
        "    # ...which starts immediately after the previous phrase\n",
        "    if rec['start'] == end_prev:\n",
        "      print(\"new starts where expected\")\n",
        "      current_phrase.append(rec['token'])\n",
        "      start_prev = rec['start']\n",
        "      end_prev = rec['end']\n",
        "      continue\n",
        "    \n",
        "    # ...or else there's a gap between when the last phrase ended and this one starts,\n",
        "    # and I'm frankly not sure how I want to adress that yet.\n",
        "    else:\n",
        "      #raise NotImplementedError\n",
        "      # let's just do.. this? for now? I guess?\n",
        "      print(\"ruh roh\")\n",
        "      current_phrase.append(rec['token'])\n",
        "      start_prev = rec['start']\n",
        "      end_prev = rec['end']\n",
        "      continue\n",
        "\n",
        "  prompt_starts = [\n",
        "    {'ts':rec['start'],\n",
        "    'td':dt.timedelta(seconds=rec['start']),\n",
        "    'prompt':' '.join(rec['tokens'])\n",
        "    }\n",
        "    for rec in token_large_phrase_segmentations]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy79XVoH51x-",
        "outputId": "5356d20b-50a4-47d3-b8f5-4c059bf6cad4"
      },
      "outputs": [],
      "source": [
        "for rec in token_large_phrase_segmentations:\n",
        "  print(f\"[{rec['start']} -> {rec['end']}] {' '.join(rec['tokens'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVv8HCJb-ryq",
        "outputId": "60d5bca4-6373-4c8f-a89f-17f96d5d8d72"
      },
      "outputs": [],
      "source": [
        "# to do: write this into the storyboard\n",
        "prompt_starts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYfoKmcZZd8q"
      },
      "outputs": [],
      "source": [
        "#tokenized_prompts_tiny\n",
        "#prompt_starts\n",
        "# to do: I should be able to modify timings on this object without needing to regenerate frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWskqZTH7Vn_"
      },
      "outputs": [],
      "source": [
        "#?model.transcribe # DecodingOptions probably contains timestamp prediction thing\n",
        "# https://github.com/openai/whisper/blob/main/whisper/decoding.py#L72\n",
        "# - without_timestamps already defaults to False, which is what we want\n",
        "\n",
        "###############\n",
        "\n",
        "# another candidate from google:\n",
        "# - https://tfhub.dev/s?q=trillsson\n",
        "# - https://ai.googleblog.com/2022/03/trillsson-small-universal-speech.html\n",
        "# and another (is there a checkpoint?)\n",
        "# - https://arxiv.org/pdf/2109.13226.pdf\n",
        "# one more...\n",
        "# - cap12 embeddings - https://arxiv.org/abs/2110.04621"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QCvP6DH_D4U"
      },
      "outputs": [],
      "source": [
        "### This cell aligns the user-provided lyrics with the timestamped tokens\n",
        "\n",
        "# to do: make this compatible with the whisper segmentation\n",
        "# to do: trigger this cell based on storyboard state\n",
        "if False:\n",
        "\n",
        "  prompts = [p.strip() for p in user_provided_captions.split('\\n') if p.strip()]\n",
        "\n",
        "  tokenized_prompts = [\n",
        "      [remove_punctuation(tok) for tok in prompt.lower().split()] for prompt in prompts\n",
        "  ]\n",
        "\n",
        "  # assign each prompt token a unique index, and let's just try to map those indices into\n",
        "  # the timestamped stuff.\n",
        "\n",
        "  if whisper_seg:\n",
        "    prompt_starts = whisper_segmentation\n",
        "    # make sure we respect the duration of the previous phrase\n",
        "    \n",
        "  else:\n",
        "\n",
        "    idx = 0\n",
        "    prompt_token_indices = []\n",
        "    flattened_prompts = []\n",
        "    for prompt in tokenized_prompts:\n",
        "        prompt_ = []\n",
        "        for tok in prompt:\n",
        "          prompt_.append(idx)\n",
        "          flattened_prompts.append(tok)\n",
        "          idx+=1\n",
        "        prompt_token_indices.append(prompt_)\n",
        "\n",
        "\n",
        "    ### using spacy's tokenization alignment\n",
        "\n",
        "    flattened_ts = [rec['tok'] for rec in token_start_times]\n",
        "    prompt2ts, ts2prompt = tokenizations.get_alignments(\n",
        "        flattened_prompts,\n",
        "        flattened_ts\n",
        "    )\n",
        "\n",
        "    prompt_idx = 0\n",
        "    prompt_starts = [{'ts':token_start_times[0]['ts'],\n",
        "                      'td':token_start_times[0]['td'],\n",
        "                      'prompt':prompts[0],\n",
        "                      }]\n",
        "    for i, result in enumerate(prompt2ts):\n",
        "      if not result:\n",
        "        continue\n",
        "      j = result[0]\n",
        "      start_rec = token_start_times[j]\n",
        "      prompt = prompt_token_indices[prompt_idx]\n",
        "      if i > prompt[-1]:\n",
        "        prompt_idx+=1\n",
        "        prompt_indices = prompt_token_indices[prompt_idx]\n",
        "        prompt = prompts[prompt_idx]\n",
        "        prompt_starts.append(\n",
        "            {'ts':start_rec['ts'],\n",
        "            'td':start_rec['td'],\n",
        "            'prompt':prompt}\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_WH4yvk5_UDp"
      },
      "outputs": [],
      "source": [
        "### This cell computes how many frames are needed for each segment\n",
        "### based on the start times for each prompt\n",
        "\n",
        "import datetime as dt\n",
        "fps = storyboard.params.fps\n",
        "\n",
        "ifps = dt.timedelta(seconds=1/fps)\n",
        "\n",
        "# estimate video end\n",
        "video_duration = dt.timedelta(seconds=helper.info['duration'])\n",
        "\n",
        "# dummy prompt for last scene duration\n",
        "prompt_starts.append({'td':video_duration})\n",
        "\n",
        "# make sure we respect the duration of the previous phrase\n",
        "frame_start=dt.timedelta(seconds=0)\n",
        "prompt_starts[0]['anim_start']=frame_start\n",
        "for i, rec in enumerate(prompt_starts[1:], start=1):\n",
        "  rec_prev = prompt_starts[i-1]\n",
        "  k=0\n",
        "  while rec_prev['anim_start'] + k*ifps < rec['td']:\n",
        "    k+=1\n",
        "  k-=1\n",
        "  rec_prev['frames'] = k\n",
        "  rec_prev['anim_duration'] = k*ifps\n",
        "  frame_start+=k*ifps\n",
        "  rec['anim_start']=frame_start\n",
        "\n",
        "# make sure we respect the duration of the previous phrase\n",
        "# to do: push end time into a timedelta and consider it... somewhere near here\n",
        "for i, rec1 in enumerate(prompt_starts):\n",
        "    rec0 = prompt_starts[i-1]\n",
        "    rec0['duration'] = rec1['td'] - rec0['td']\n",
        "\n",
        "# drop the dummy frame\n",
        "prompt_starts = prompt_starts[:-1]\n",
        "\n",
        "# to do: given a 0 duration prompt, assume its duration is captured in the next prompt \n",
        "#        and guesstimate a corrected prompt start time and duration \n",
        "\n",
        "\n",
        "#for rec in prompt_starts:\n",
        "#  print(\n",
        "#      f\"[{rec['anim_start']} | {rec['ts']}] [{rec['duration']} | {rec['anim_duration']}] - {rec['frames']} - {rec['prompt']}\"\n",
        "#  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVpry9m-UbhT",
        "outputId": "4761374b-edc9-4a92-d9ad-4b5740ca43ee"
      },
      "outputs": [],
      "source": [
        "# to do: use this object to loop over prompts and attach scene-specific settings to the dict\n",
        "# when generating, attach the base image and the variations as well\n",
        "# this gives users and interception point where they could e.g. specify a base/init image to get variations for\n",
        "#prompt_starts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sh514DGj_sua",
        "outputId": "58d1b72a-0953-4fca-9e24-d7832e3f50e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0:00:00 | 0] [0:00:08.320000 | 0:00:08.249967] - 99 - Global controls will have to be imposed and a world governing body will be created to enforce them\n",
            "getting init image\n",
            "constructed request\n"
          ]
        }
      ],
      "source": [
        "# generate animation\n",
        "\n",
        "frames = []\n",
        "theme_prompt = storyboard.params.theme_prompt\n",
        "optimal_ordering = storyboard.params.optimal_ordering\n",
        "add_caption = storyboard.params.add_caption\n",
        "display_frames_as_we_get_them = storyboard.params.display_frames_as_we_get_them\n",
        "max_frames = storyboard.params.max_frames\n",
        "image_consistency = storyboard.params.image_consistency\n",
        "n_variations = storyboard.params.n_variations\n",
        "\n",
        "from vktrs.api import (\n",
        "    get_image_for_prompt\n",
        ")\n",
        "from vktrs.tsp import (\n",
        "    tsp_permute_frames,\n",
        "    batched_tsp_permute_frames,\n",
        ")\n",
        "\n",
        "for rec in prompt_starts:\n",
        "    print(\n",
        "        f\"[{rec['anim_start']} | {rec['ts']}] [{rec['duration']} | {rec['anim_duration']}] - {rec['frames']} - {rec['prompt']}\"\n",
        "    )\n",
        "    lyric = rec['prompt']\n",
        "    #n_variations = rec['frames']\n",
        "    prompt = f\"{lyric}, {theme_prompt}\"\n",
        "    #images = get_close_variations_from_prompt(prompt, n_variations=n_variations, image_consistency=image_consistency)\n",
        "    if rec.get('frame0') is None:\n",
        "        #rec['frame0'] = init_image = list(get_image_for_prompt(prompt))[0]\n",
        "        print(\"getting init image\")\n",
        "        img_gen = get_image_for_prompt(prompt)\n",
        "        print('constructed request')\n",
        "        imgs0 = list(img_gen)\n",
        "        print(\"got response\")\n",
        "        rec['frame0'] = init_image = imgs0[0]\n",
        "        print(\"got image\")\n",
        "    # to do: use SDK args to request multiple images in single request...\n",
        "    images = []\n",
        "    #rec['variations'] = get_variations_w_init(prompt, images[0], start_schedule=(1-image_consistency))[0]\n",
        "    for _ in range(n_variations - 1):\n",
        "      img = get_variations_w_init(prompt, init_image, start_schedule=(1-image_consistency))[0]\n",
        "      images.append(img)\n",
        "    rec['variations'] = images\n",
        "    images = [rec['frame0']] + images\n",
        "\n",
        "    if optimal_ordering:\n",
        "        images = batched_tsp_permute_frames(\n",
        "            images,\n",
        "            max_variations_per_opt_pass\n",
        "        )\n",
        "    rec['images'] = rec['images_raw'] = images\n",
        "\n",
        "\n",
        "    if add_caption:\n",
        "        rec['images'] = [add_caption2image(im, lyric) for im in rec['images']]\n",
        "\n",
        "    if display_frames_as_we_get_them:\n",
        "        print(lyric)\n",
        "        for im in images:\n",
        "            display(im)\n",
        "\n",
        "    #images *= repeat\n",
        "    sequence = []\n",
        "    frame_factory = cycle(images)\n",
        "    while len(sequence) < rec['frames']:\n",
        "        sequence.append(next(frame_factory))\n",
        "    frames.extend(sequence)\n",
        "    if len(frames) >= max_frames:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ts': 0,\n",
              " 'td': datetime.timedelta(0),\n",
              " 'prompt': 'Global controls will have to be imposed and a world governing body will be created to enforce them',\n",
              " 'anim_start': datetime.timedelta(0),\n",
              " 'frames': 99,\n",
              " 'anim_duration': datetime.timedelta(seconds=8, microseconds=249967),\n",
              " 'duration': datetime.timedelta(seconds=8, microseconds=320000)}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "666ac0372b084ecbb0110fdedf0fca7a",
            "aea5ff423a984afc85aafff3357d1d04",
            "7348231ab4b040a4b557dcc54b66e91b",
            "162af22fd6d444c282fc8df83988c1c7",
            "cd21c612dba446a18dc67ce94ef51e1d",
            "0bd09e6456854b5d8a8ddb2b5ae60f33",
            "f7b6b18a2140424aacb888c09b679a71",
            "d206bf0a4f2d438d937ca923bca3ffae",
            "857a8e63525a4e00a8f47d66f5007247",
            "8627238a441b47b8884e84dca9a2a02d",
            "2b5ff8491c984c61b55b09c452f1c510"
          ]
        },
        "id": "cEwFI6kA_2SH",
        "outputId": "b71feb36-8571-45e1-9f30-816b900a7bd9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "666ac0372b084ecbb0110fdedf0fca7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3204 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding video...\n",
            "Video complete.\n",
            "Video saved to: output.mp4\n"
          ]
        }
      ],
      "source": [
        "# @title # 6. 🎥 Compile your video!\n",
        "\n",
        "#input_audio = '/content/Ai Generated Music Video - Deltron 3030 - Virus [WJaxFbdjm8c].webm'\n",
        "\n",
        "# to do: add this to dmarx/fine ...which really needs a better name. as usual.\n",
        "\n",
        "input_audio = 'audio.mp3'\n",
        "\n",
        "cmd_in = ['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-']\n",
        "cmd_out = ['-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '1', '-preset', 'veryslow', '-shortest', output_filename]\n",
        "\n",
        "if input_audio:\n",
        "  cmd_in += ['-i', str(input_audio), '-acodec', 'libmp3lame']\n",
        "\n",
        "cmd = cmd_in + cmd_out\n",
        "\n",
        "p = Popen(cmd, stdin=PIPE)\n",
        "#for im in tqdm(chain(frames)):\n",
        "for im in tqdm(frames):\n",
        "  im.save(p.stdin, 'PNG')\n",
        "p.stdin.close()\n",
        "\n",
        "print(\"Encoding video...\")\n",
        "p.wait()\n",
        "print(\"Video complete.\")\n",
        "print(f\"Video saved to: {output_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esjAqavcAWmA",
        "outputId": "5dfd89d1-4ad0-49de-af66-e26bd81f7118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output.mp4\n"
          ]
        }
      ],
      "source": [
        "!tar -czvf output.tar.gz output.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBKVymvtFymZ"
      },
      "source": [
        "# to do\n",
        "\n",
        "## on-disk storyboard\n",
        "\n",
        "* animation specified by a config file. assumed to start empty but doesn't need to. whether or not to perform a step is determined by whether or not the config file is populated\n",
        "* after url is downloaded, subtitles and audio files get logged in config\n",
        "* after prompts are parsed, prompts and start times go into config\n",
        "* frame counts and animation start times\n",
        "* variations to compute per scene\n",
        "* init_images, generated as needed. locations logged in config\n",
        "\n",
        "* **final intervention point** presenting the storyboard to the user somehow for approval would be nice\n",
        "\n",
        "* variations generated\n",
        "* video compiled\n",
        "\n",
        "\n",
        "## workflow changes\n",
        "* generate single prompts first and then circle back to variations after. Give user an opportunity to re-generate prompts before committing to the variation generation\n",
        "  - add some sort of 'storyboard' experience\n",
        "* separately save image outputs and images with text overlaid\n",
        "* facilitate \"resume\" operation for generating (more) variations from a particular prompt \n",
        "* if possible try to come up with a way to sync visual vibration rate with audio beat\n",
        "* wrap subtitle2prompts utility\n",
        "* add mechanism for auto-extracting lyrics based on scene duration and target tokens per prompt\n",
        "* think about how to port this into deforum\n",
        "* optionally encode segments separately\n",
        "* Permit user to specify non-english base language\n",
        "  - still download and use en captions for translated prompts?\n",
        "  - use base language captions for prompt alignment\n",
        "  - use user-specified lyrics in base language to paste over images"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPITAFUYQs32mF/EC4yqIY1",
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('dmarx-je5LfYh2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "57881a85d677a34ea29564e0084ef84f4058c4e30a2bb466eb0e0b908d0628df"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0302dce789e54cdb96202b54ff0aa8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bd09e6456854b5d8a8ddb2b5ae60f33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8cae5d21d24d4e8c5d43cc4569676e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1148a9f2996747448a902189021ab753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "162af22fd6d444c282fc8df83988c1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8627238a441b47b8884e84dca9a2a02d",
            "placeholder": "​",
            "style": "IPY_MODEL_2b5ff8491c984c61b55b09c452f1c510",
            "value": " 3204/3204 [05:09&lt;00:00, 10.69it/s]"
          }
        },
        "1dd8b1c7a5b84c359392957ebf15fa43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a75aba78b0fe441bb016de8e533e2e04",
            "placeholder": "​",
            "style": "IPY_MODEL_0302dce789e54cdb96202b54ff0aa8fb",
            "value": ""
          }
        },
        "2b5ff8491c984c61b55b09c452f1c510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "666ac0372b084ecbb0110fdedf0fca7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aea5ff423a984afc85aafff3357d1d04",
              "IPY_MODEL_7348231ab4b040a4b557dcc54b66e91b",
              "IPY_MODEL_162af22fd6d444c282fc8df83988c1c7"
            ],
            "layout": "IPY_MODEL_cd21c612dba446a18dc67ce94ef51e1d"
          }
        },
        "7145a43cc7704bfea46f9f106a06f990": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1148a9f2996747448a902189021ab753",
            "placeholder": "​",
            "style": "IPY_MODEL_0e8cae5d21d24d4e8c5d43cc4569676e",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "7348231ab4b040a4b557dcc54b66e91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d206bf0a4f2d438d937ca923bca3ffae",
            "max": 3204,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_857a8e63525a4e00a8f47d66f5007247",
            "value": 3204
          }
        },
        "7ba7cfb4b2f843f9ae7dea6edc8471b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e55da1a7b9b49fd9333861c98d7354a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c01e4d9874c441cbad5495ac6629b028",
            "value": 0
          }
        },
        "857a8e63525a4e00a8f47d66f5007247": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8627238a441b47b8884e84dca9a2a02d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e55da1a7b9b49fd9333861c98d7354a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a75aba78b0fe441bb016de8e533e2e04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aea5ff423a984afc85aafff3357d1d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bd09e6456854b5d8a8ddb2b5ae60f33",
            "placeholder": "​",
            "style": "IPY_MODEL_f7b6b18a2140424aacb888c09b679a71",
            "value": "100%"
          }
        },
        "afcf916e6878438a8af4aae964490265": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dd8b1c7a5b84c359392957ebf15fa43",
              "IPY_MODEL_7ba7cfb4b2f843f9ae7dea6edc8471b1",
              "IPY_MODEL_7145a43cc7704bfea46f9f106a06f990"
            ],
            "layout": "IPY_MODEL_bc93a3f7ecf04d64ac253dab98f645cb"
          }
        },
        "bc93a3f7ecf04d64ac253dab98f645cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c01e4d9874c441cbad5495ac6629b028": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd21c612dba446a18dc67ce94ef51e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d206bf0a4f2d438d937ca923bca3ffae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b6b18a2140424aacb888c09b679a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
